# modules/blog/image_processor.py
import os
import cv2
import numpy as np
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
from torchvision.models import resnet18
from django.conf import settings
import logging
from typing import Tuple, List, Dict, Optional  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã —Ç–∏–ø–æ–≤
import shutil  # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏–º–ø–æ—Ä—Ç—ã


logger = logging.getLogger(__name__)

class PredictionConfig:
    img_size = 64  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏

class ImageProcessor:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = self._load_model()
        self.base_output_dir = os.path.join(settings.MEDIA_ROOT, 'processed_images')
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        os.makedirs(self.base_output_dir, exist_ok=True)

    class CustomResNet(nn.Module):
        def __init__(self):
            super().__init__()
            self.resnet = resnet18(pretrained=False)
            self.resnet.fc = nn.Sequential(
                nn.Linear(self.resnet.fc.in_features, 512),
                nn.ReLU(),
                nn.Dropout(0.5),
                nn.Linear(512, 1)
            )

        def forward(self, x):
            return torch.sigmoid(self.resnet(x))
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        model = self.CustomResNet().to(self.device)
        model_path = os.path.join(settings.BASE_DIR, 'best_model.pth')
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
        
        model.load_state_dict(torch.load(model_path, map_location=self.device))
        model.eval()
        return model
    
    def format_processing_results(self, squares_data):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML-–æ—Ç—á—ë—Ç —Å —É–∑–∫–∏–º —Å—Ç–æ–ª–±—Ü–æ–º –æ—Ç–º–µ—Ç–æ–∫
        """
        result = """
        <div style='font-family: monospace; max-width: 500px;'>
        <h3 style='color: #2c3e50; margin-bottom: 10px;'>üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —à–∞–±–ª–æ–Ω–æ–≤</h3>
        """
        
        for template, questions in squares_data.items():
            result += f"""
            <div style='margin-bottom: 25px;'>
                <h4 style='color: #3498db; margin: 5px 0;'>üìã –®–∞–±–ª–æ–Ω: {template}</h4>
                <table style='width: 100%; border-collapse: collapse; font-size: 14px;'>
                    <thead>
                        <tr style='background-color: #f8f9fa;'>
                            <th style='padding: 6px; border: 1px solid #dee2e6; text-align: center; width: 30%;'>–í–æ–ø—Ä–æ—Å ‚Ññ</th>
                            <th style='padding: 6px; border: 1px solid #dee2e6; text-align: center; width: 30%;'>–û—Ç–º–µ—Ç–∫–∏</th>
                        </tr>
                    </thead>
                    <tbody>
            """
            
            for question, answers in sorted(questions.items(), key=lambda x: int(x[0])):
                marked = [a for a, s in sorted(answers.items()) if s == "marked"]
                marks = " ".join(f"<span style='color: #28a745;'>‚úì{a}</span>" for a in marked) if marked else "<span style='color: #dc3545;'>‚úó</span>"
                
                result += f"""
                    <tr>
                        <td style='padding: 6px; border: 1px solid #dee2e6; text-align: center;'>{question}</td>
                        <td style='padding: 6px; border: 1px solid #dee2e6; text-align: center;'>{marks}</td>
                    </tr>
                """
            
            result += """
                    </tbody>
                </table>
            </div>
            """
        
        result += "</div>"
        return result
    

    def _load_and_preprocess_image(self, image_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –µ–≥–æ –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ."""
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        return image, gray

    def _get_marker_corners(self, contour: np.ndarray) -> np.ndarray:
        """–ù–∞—Ö–æ–¥–∏—Ç 4 —É–≥–ª–∞ –º–∞—Ä–∫–µ—Ä–∞ —Å –ø–æ–º–æ—â—å—é –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ –∫–æ–Ω—Ç—É—Ä–∞."""
        epsilon = 0.02 * cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, epsilon, True)

        if len(approx) != 4:
            rect = cv2.minAreaRect(contour)
            box = cv2.boxPoints(rect)
            approx = np.int0(box)

        approx = approx.reshape(4, 2)
        center = approx.mean(axis=0)
        angles = np.arctan2(approx[:, 1] - center[1], approx[:, 0] - center[0])
        sorted_idx = np.argsort(angles)
        return approx[sorted_idx]

    def _find_markers(self, gray_image: np.ndarray, min_area: int = 500, max_area: int = 5000) -> List[np.ndarray]:
        """–ù–∞—Ö–æ–¥–∏—Ç —É–≥–ª–æ–≤—ã–µ –º–∞—Ä–∫–µ—Ä—ã (—á–µ—Ä–Ω—ã–µ –∫–≤–∞–¥—Ä–∞—Ç—ã) –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."""
        thresh = cv2.adaptiveThreshold(
            gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 51, 5
        )

        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        markers = []
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if min_area < area < max_area:
                x, y, w, h = cv2.boundingRect(cnt)
                aspect_ratio = float(w) / h
                if 0.8 < aspect_ratio < 1.2:
                    corners = self._get_marker_corners(cnt)
                    markers.append(corners)

        return markers

    def _normalize_image(
            self,
            image: np.ndarray,
            markers: List[np.ndarray],
            output_path: str,
            output_size: Tuple[int, int] = (1000, 1500),
            crop_percent: int = 10,
    ) -> Optional[np.ndarray]:
        """–í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –æ–±—Ä–µ–∑–∞–µ—Ç –≤–µ—Ä—Ö/–Ω–∏–∑, —á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å –º–∞—Ä–∫–µ—Ä—ã."""
        markers_array = np.array(markers)
        centers = np.array([np.mean(marker, axis=0) for marker in markers_array])

        sorted_indices = np.argsort(centers[:, 1])
        top_indices = sorted_indices[:2]
        bottom_indices = sorted_indices[2:]
        top_sorted = top_indices[np.argsort(centers[top_indices, 0])]
        bottom_sorted = bottom_indices[np.argsort(centers[bottom_indices, 0])[::-1]]
        final_order = np.concatenate([top_sorted, bottom_sorted])
        centers_sorted = centers[final_order]

        src_points = np.float32(centers_sorted)
        width, height = output_size
        dst_points = np.float32([[0, 0], [width, 0], [width, height], [0, height]])

        matrix = cv2.getPerspectiveTransform(src_points, dst_points)
        result = cv2.warpPerspective(image, matrix, (width, height))

        crop_pixels = int(height * crop_percent / 100)
        result = result[crop_pixels: height - crop_pixels, :]

        cv2.imwrite(output_path, result, [int(cv2.IMWRITE_JPEG_QUALITY), 90])
        return result

    def _extract_numbered_rectangles(
            self,
            input_image_path: str,
            output_folder: str,
            expected_count: int = 20,
            min_area: int = 20000,
            max_area: int = 50000,
            aspect_ratio_range: Tuple[float, float] = (4.5, 7.5)
    ) -> List[Tuple[int, int, int, int]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π –¥–ª—è –¥–≤—É—Ö —Å—Ç–æ–ª–±—Ü–æ–≤."""
        image = cv2.imread(input_image_path)
        if image is None:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {input_image_path}")

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        thresh = cv2.adaptiveThreshold(
            blurred, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 51, 7
        )

        kernel = np.ones((3, 3), np.uint8)
        processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)

        contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        rectangles = []
        for cnt in contours:
            x, y, w, h = cv2.boundingRect(cnt)
            area = w * h
            aspect_ratio = max(w, h) / min(w, h)

            if (min_area <= area <= max_area) and (aspect_ratio_range[0] <= aspect_ratio <= aspect_ratio_range[1]):
                rectangles.append((x, y, w, h))

        if len(rectangles) >= 2:
            x_coords = [r[0] for r in rectangles]
            median_x = np.median(x_coords)

            left_col = [r for r in rectangles if r[0] < median_x]
            right_col = [r for r in rectangles if r[0] >= median_x]

            left_col.sort(key=lambda r: r[1])
            right_col.sort(key=lambda r: r[1])

            rectangles = left_col[:10] + right_col[:10]

        base_name = os.path.splitext(os.path.basename(input_image_path))[0]

        for i, (x, y, w, h) in enumerate(rectangles[:expected_count], 1):
            roi = image[y:y + h, x:x + w]
            output_path = os.path.join(output_folder, f"{base_name}_{i}.jpg")
            cv2.imwrite(output_path, roi)

        return rectangles[:expected_count]

    def _find_squares(
            self,
            image: np.ndarray,
            min_area: int = 2000,
            max_area: int = 3000
    ) -> Tuple[List[Tuple[int, int, int, int]], List[Dict]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–≤–∞–¥—Ä–∞—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)

        thresh = cv2.adaptiveThreshold(
            blurred, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 31, 5
        )

        kernel = np.ones((3, 3), np.uint8)
        processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)

        contours, _ = cv2.findContours(processed, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

        squares = []
        rejected = []

        for cnt in contours:
            epsilon = 0.02 * cv2.arcLength(cnt, True)
            approx = cv2.approxPolyDP(cnt, epsilon, True)
            x, y, w, h = cv2.boundingRect(cnt)
            area = w * h
            aspect_ratio = float(w) / h
            vertices = len(approx)

            if (vertices == 4 and min_area <= area <= max_area and 
                0.8 <= aspect_ratio <= 1.2 and cv2.isContourConvex(approx)):
                squares.append((x, y, w, h))
            else:
                rejected.append({
                    "position": (x, y, w, h),
                    "area": area,
                    "aspect_ratio": aspect_ratio,
                    "vertices": vertices
                })

        squares.sort(key=lambda s: s[0])
        return squares, rejected

    def _process_squares(self, input_folder: str, output_folder: str) -> Dict[str, Dict[int, Dict[int, str]]]:

        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
        results = {}
        
        for filename in sorted(os.listdir(input_folder)):
            if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue

            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —à–∞–±–ª–æ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Bushueva –∏–∑ Bushueva_czmgvHD_norm_1_square_2_empty.jpg)
                template_name = filename.split('_')[0]
                if template_name not in results:
                    results[template_name] = {}

                file_path = os.path.join(input_folder, filename)
                image = cv2.imread(file_path)
                if image is None:
                    continue

                squares, _ = self._find_squares(image)
                base_name = os.path.splitext(filename)[0]
                
                for i, (x, y, w, h) in enumerate(squares, 1):
                    square_img = image[y:y + h, x:x + w]
                    square_filename = f"{base_name}_square_{i}.jpg"
                    output_path = os.path.join(output_folder, square_filename)
                    cv2.imwrite(output_path, square_img)

                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    prediction = self._predict_square(output_path)
                    status = "empty" if prediction == 0 else "marked"
                    
                    new_filename = f"{base_name}_square_{i}_{status}.jpg"
                    new_path = os.path.join(output_folder, new_filename)
                    os.rename(output_path, new_path)

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1 –∏–∑ Bushueva_czmgvHD_norm_1)
                    question_number = int(base_name.split('_')[-1])
                    
                    if question_number not in results[template_name]:
                        results[template_name][question_number] = {}

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ marked –æ—Ç–≤–µ—Ç—ã
                    if status == "marked":
                        results[template_name][question_number][i] = status

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –≤ {filename}: {str(e)}")

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫–æ–Ω—Å–æ–ª—å
        print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —à–∞–±–ª–æ–Ω–æ–≤:")
        for template, questions in results.items():
            print(f"\n–®–∞–±–ª–æ–Ω: {template}")
            for question, answers in sorted(questions.items()):
                print(f"  –í–æ–ø—Ä–æ—Å {question}:")
                for answer, status in sorted(answers.items()):
                    print(f"    –í–∞—Ä–∏–∞–Ω—Ç {answer}: {status}")
        
        return results


    def _predict_square(self, image_path: str) -> int:
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–≤–∞–¥—Ä–∞—Ç–∞ (0 - –ø—É—Å—Ç–æ–π, 1 - –ø–æ–º–µ—á–µ–Ω–Ω—ã–π)"""
        transform = transforms.Compose([
            transforms.Resize((PredictionConfig.img_size, PredictionConfig.img_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        try:
            image = Image.open(image_path).convert('RGB')
            image = transform(image).unsqueeze(0).to(self.device)

            with torch.no_grad():
                output = self.model(image)
                return (output > 0.5).float().item()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {image_path}: {str(e)}")
            return 0
        
    def process_uploaded_image(self, image_path: str) -> Dict:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        """
        try:
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            base_name = os.path.splitext(os.path.basename(image_path))[0]
            session_dir = os.path.join(self.base_output_dir, base_name)
            
            output_norm_folder = os.path.join(session_dir, 'normalized')
            output_rectangles_folder = os.path.join(session_dir, 'rectangles')
            output_squares_folder = os.path.join(session_dir, 'squares')
            
            os.makedirs(output_norm_folder, exist_ok=True)
            os.makedirs(output_rectangles_folder, exist_ok=True)
            os.makedirs(output_squares_folder, exist_ok=True)

            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            image, gray = self._load_and_preprocess_image(image_path)

            # 2. –ü–æ–∏—Å–∫ –º–∞—Ä–∫–µ—Ä–æ–≤
            markers = self._find_markers(gray)
            if len(markers) != 4:
                return {"error": f"–ù–∞–π–¥–µ–Ω–æ {len(markers)} –º–∞—Ä–∫–µ—Ä–æ–≤ (—Ç—Ä–µ–±—É–µ—Ç—Å—è 4)"}

            # 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            norm_output_path = os.path.join(output_norm_folder, f"{base_name}_norm.jpg")
            normalized = self._normalize_image(image, markers, norm_output_path)
            if normalized is None:
                return {"error": "–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é"}

            # 4. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤
            rectangles = self._extract_numbered_rectangles(
                norm_output_path,
                output_rectangles_folder
            )

            # 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤
            squares_data = self._process_squares(
                output_rectangles_folder,
                output_squares_folder
            )

            return {
                "success": True,
                "raw_data": squares_data,
                "formatted_html": self.format_processing_results(squares_data)
            }
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {str(e)}")
            return {"error": str(e)}
        
        finally:
        # –í—Å–µ–≥–¥–∞ –æ—á–∏—â–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if session_dir:
                self._cleanup_processing_files(session_dir)

    # def compare_with_reference(self, reference_data, current_data):
    #     """
    #     –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ç–∫—É —Å —Ä–∞–∑–ª–∏—á–∏—è–º–∏.
    #     """
    #     comparison_results = {}
        
    #     # –ï—Å–ª–∏ reference_data - —ç—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç process_uploaded_image, –∏–∑–≤–ª–µ–∫–∞–µ–º raw_data
    #     ref_data = reference_data.get('raw_data', {}) if isinstance(reference_data, dict) else {}
    #     curr_data = current_data.get('raw_data', {}) if isinstance(current_data, dict) else {}
    #     print("!!! ref_data-",ref_data)
    #     print("!!! curr_data-",curr_data)

    #     for template, questions in curr_data.items():
    #         comparison_results[template] = {}
            
    #         for question, answers in questions.items():
    #             comparison_results[template][question] = {}
                
    #             # –ü–æ–ª—É—á–∞–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
    #             ref_answers = ref_data.get(template, {}).get(question, {})
                
    #             for answer, status in answers.items():
    #                 # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–æ—Ç –æ—Ç–≤–µ—Ç –≤ —ç—Ç–∞–ª–æ–Ω–µ
    #                 if answer in ref_answers:
    #                     comparison_results[template][question][answer] = "correct"
    #                 else:
    #                     comparison_results[template][question][answer] = "incorrect"
    #     print("!!!",comparison_results)
    #     return comparison_results


    def compare_with_reference(self, reference_data, current_data):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏.
        –û—Ç–≤–µ—Ç —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º, –µ—Å–ª–∏ –æ–Ω —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —ç—Ç–∞–ª–æ–Ω–æ–º –¥–ª—è —Ç–æ–≥–æ –∂–µ –≤–æ–ø—Ä–æ—Å–∞.
        """
        comparison_results = {}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º raw_data –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        ref_data = reference_data.get('raw_data', {}) if isinstance(reference_data, dict) else {}
        curr_data = current_data.get('raw_data', {}) if isinstance(current_data, dict) else {}
        
        print("!!! ref_data-", ref_data)
        print("!!! curr_data-", curr_data)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –∫–∞–∫ incorrect
        if not ref_data:
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
            return self._mark_all_as_incorrect(curr_data)
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ç–∞–º –æ–¥–∏–Ω —à–∞–±–ª–æ–Ω)
        ref_template, ref_questions = next(iter(ref_data.items())) if ref_data else (None, {})
        
        for curr_template, curr_questions in curr_data.items():
            comparison_results[curr_template] = {}
            
            for question, answers in curr_questions.items():
                comparison_results[curr_template][question] = {}
                
                # –ü–æ–ª—É—á–∞–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ (–∏–∑ –ª—é–±–æ–≥–æ —à–∞–±–ª–æ–Ω–∞)
                ref_answers = ref_questions.get(question, {})
                
                for answer, status in answers.items():
                    # –û—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, –µ—Å–ª–∏ —Ç–∞–∫–æ–π –∂–µ –æ—Ç–≤–µ—Ç –µ—Å—Ç—å –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –≤ —ç—Ç–∞–ª–æ–Ω–µ
                    if answer in ref_answers:
                        comparison_results[curr_template][question][answer] = "correct"
                    else:
                        comparison_results[curr_template][question][answer] = "incorrect"
        
        print("!!! comparison_results-", comparison_results)
        return comparison_results


    def format_comparison_results(self, comparison_data):
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ HTML —Å —Ü–≤–µ—Ç–æ–≤–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π.
        """
        result = """
        <div style='font-family: monospace; max-width: 500px;'>
        <h3 style='color: #2c3e50; margin-bottom: 10px;'>üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏</h3>
        <p style='color: #6c757d; margin-bottom: 15px;'>
            <span style='color: #28a745;'>‚úì</span> - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —ç—Ç–∞–ª–æ–Ω—É<br>
            <span style='color: #dc3545;'>‚úó</span> - –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —ç—Ç–∞–ª–æ–Ω—É
        </p>
        """
        
        for template, questions in comparison_data.items():
            result += f"""
            <div style='margin-bottom: 25px;'>
                <h4 style='color: #3498db; margin: 5px 0;'>üìã –®–∞–±–ª–æ–Ω: {template}</h4>
                <table style='width: 100%; border-collapse: collapse; font-size: 14px;'>
                    <thead>
                        <tr style='background-color: #f8f9fa;'>
                            <th style='padding: 6px; border: 1px solid #dee2e6; text-align: center; width: 30%;'>–í–æ–ø—Ä–æ—Å ‚Ññ</th>
                            <th style='padding: 6px; border: 1px solid #dee2e6; text-align: center; width: 30%;'>–û—Ç–º–µ—Ç–∫–∏</th>
                        </tr>
                    </thead>
                    <tbody>
            """
            
            for question, answers in sorted(questions.items(), key=lambda x: int(x[0])):
                marks = []
                for answer, status in sorted(answers.items()):
                    if status == "correct":
                        marks.append(f"<span style='color: #28a745;'>‚úì{answer}</span>")
                    else:
                        marks.append(f"<span style='color: #dc3545;'>‚úó{answer}</span>")
                
                marks_str = " ".join(marks) if marks else "<span style='color: #6c757d;'>–Ω–µ—Ç –æ—Ç–º–µ—Ç–æ–∫</span>"
                
                result += f"""
                    <tr>
                        <td style='padding: 6px; border: 1px solid #dee2e6; text-align: center;'>{question}</td>
                        <td style='padding: 6px; border: 1px solid #dee2e6; text-align: center;'>{marks_str}</td>
                    </tr>
                """
            
            result += """
                    </tbody>
                </table>
            </div>
            """
        
        result += "</div>"
        return result
    
    def _cleanup_processing_files(self, session_dir: str):
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        try:
            if os.path.exists(session_dir):
                shutil.rmtree(session_dir)
                logger.info(f"–£–¥–∞–ª–µ–Ω–∞ –ø–∞–ø–∫–∞ —Å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏: {session_dir}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {str(e)}")