# -*- coding: utf-8 -*-
"""MAINN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EVs6nHWg1-Iiu4JFI9KfkD4MxmUqxYQQ
"""

import cv2
import numpy as np
import os
from typing import List, Tuple, Optional, Dict
import glob

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
from torchvision.models import resnet18


# Конфигурация для предсказания (должна соответствовать обучению)
class PredictionConfig:
    img_size = 64  # Размер изображений, на которых обучалась модель
    # Добавьте другие параметры, если они важны для предсказания

# Функция для предсказания на одном изображении
def predict_image(image_path, model, device):
    transform = transforms.Compose([
        transforms.Resize((PredictionConfig.img_size, PredictionConfig.img_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)

    model.eval()
    with torch.no_grad():
        output = model(image)
        prediction = (output > 0.5).float().item()
    return prediction

# Определение архитектуры модели (должна соответствовать обучению)
class CustomResNet(nn.Module):
    def __init__(self):
        super(CustomResNet, self).__init__()
        self.resnet = resnet18(pretrained=False)  # Важно: не используем предобученные веса
        # Заменяем последний слой для нашей задачи
        self.resnet.fc = nn.Sequential(
            nn.Linear(self.resnet.fc.in_features, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 1)
        )

    def forward(self, x):
        return torch.sigmoid(self.resnet(x))


def show_image(title: str, image: np.ndarray, wait: bool = True, scale: float = 0.5):
    """Вспомогательная функция для отображения изображения с возможностью масштабирования."""
    if scale != 1.0:
        h, w = image.shape[:2]
        resized = cv2.resize(image, (int(w * scale), int(h * scale)))
    else:
        resized = image

    cv2.imshow(title, resized)
    if wait:
        cv2.waitKey(0)
        cv2.destroyAllWindows()


def load_and_preprocess_image(image_path: str) -> Tuple[np.ndarray, np.ndarray]:
    """Загружает изображение и преобразует его в оттенки серого."""
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"Не удалось загрузить изображение: {image_path}")
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    return image, gray


def get_marker_corners(contour: np.ndarray) -> np.ndarray:
    """Находит 4 угла маркера с помощью аппроксимации контура."""
    epsilon = 0.02 * cv2.arcLength(contour, True)
    approx = cv2.approxPolyDP(contour, epsilon, True)

    if len(approx) != 4:
        rect = cv2.minAreaRect(contour)
        box = cv2.boxPoints(rect)
        approx = np.int0(box)

    approx = approx.reshape(4, 2)
    center = approx.mean(axis=0)
    angles = np.arctan2(approx[:, 1] - center[1], approx[:, 0] - center[0])
    sorted_idx = np.argsort(angles)
    return approx[sorted_idx]


def find_markers(gray_image: np.ndarray, min_area: int = 500, max_area: int = 5000, debug: bool = False) -> List[
    np.ndarray]:
    """Находит угловые маркеры (черные квадраты) на изображении."""
    thresh = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 51, 5)

    if debug:
        show_image("Threshold", thresh)

    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    markers = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if min_area < area < max_area:
            x, y, w, h = cv2.boundingRect(cnt)
            aspect_ratio = float(w) / h
            if 0.8 < aspect_ratio < 1.2:
                corners = get_marker_corners(cnt)
                markers.append(corners)

    if debug:
        debug_img = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)
        for marker in markers:
            for i, (px, py) in enumerate(marker):
                cv2.circle(debug_img, (int(px), int(py)), 5, (0, 255, 0), -1)
                cv2.putText(debug_img, str(i), (int(px), int(py)),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        show_image("Marker Corners", debug_img)

    return markers


def normalize_image(
        image: np.ndarray,
        markers: List[np.ndarray],
        output_path: str,
        output_size: Tuple[int, int] = (1000, 1500),
        debug: bool = False,
        crop_percent: int = 10,
) -> Optional[np.ndarray]:
    """Выравнивает изображение и обрезает верх/низ, чтобы удалить маркеры."""
    if len(markers) != 4:
        print(f"Найдено {len(markers)} маркеров (требуется 4). Невозможно выполнить нормализацию.")
        return None

    markers_array = np.array(markers)
    centers = np.array([np.mean(marker, axis=0) for marker in markers_array])

    sorted_indices = np.argsort(centers[:, 1])
    top_indices = sorted_indices[:2]
    bottom_indices = sorted_indices[2:]
    top_sorted = top_indices[np.argsort(centers[top_indices, 0])]
    bottom_sorted = bottom_indices[np.argsort(centers[bottom_indices, 0])[::-1]]
    final_order = np.concatenate([top_sorted, bottom_sorted])
    centers_sorted = centers[final_order]

    src_points = np.float32(centers_sorted)
    width, height = output_size
    dst_points = np.float32([[0, 0], [width, 0], [width, height], [0, height]])

    matrix = cv2.getPerspectiveTransform(src_points, dst_points)
    result = cv2.warpPerspective(image, matrix, (width, height))

    crop_pixels = int(height * crop_percent / 100)
    result = result[crop_pixels: height - crop_pixels, :]

    cv2.imwrite(output_path, result, [int(cv2.IMWRITE_JPEG_QUALITY), 90])
    print(f"Изображение сохранено как {output_path} (обрезано {crop_percent}% сверху/снизу)")

    return result


def extract_numbered_rectangles(
        input_image_path: str,
        output_folder: str,
        debug: bool = False,
        expected_count: int = 20,
        min_area: int = 20000,
        max_area: int = 50000,
        aspect_ratio_range: Tuple[float, float] = (4.5, 7.5)
) -> List[Tuple[int, int, int, int]]:
    """Извлекает прямоугольники с правильной нумерацией для двух столбцов."""
    os.makedirs(output_folder, exist_ok=True)

    image = cv2.imread(input_image_path)
    if image is None:
        raise ValueError(f"Не удалось загрузить изображение: {input_image_path}")

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    thresh = cv2.adaptiveThreshold(
        blurred, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV, 51, 7
    )

    kernel = np.ones((3, 3), np.uint8)
    processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)

    contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    rectangles = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        area = w * h
        aspect_ratio = max(w, h) / min(w, h)

        if (min_area <= area <= max_area) and (aspect_ratio_range[0] <= aspect_ratio <= aspect_ratio_range[1]):
            rectangles.append((x, y, w, h))

    if len(rectangles) >= 2:
        x_coords = [r[0] for r in rectangles]
        median_x = np.median(x_coords)

        left_col = [r for r in rectangles if r[0] < median_x]
        right_col = [r for r in rectangles if r[0] >= median_x]

        left_col.sort(key=lambda r: r[1])
        right_col.sort(key=lambda r: r[1])

        rectangles = left_col[:10] + right_col[:10]

    base_name = os.path.splitext(os.path.basename(input_image_path))[0]

    for i, (x, y, w, h) in enumerate(rectangles[:expected_count], 1):
        roi = image[y:y + h, x:x + w]
        output_path = os.path.join(output_folder, f"{base_name}_{i}.jpg")
        cv2.imwrite(output_path, roi)

    return rectangles[:expected_count]


def find_squares(image: np.ndarray,
                 min_area: int = 2000,
                 max_area: int = 3000,
                 debug: bool = False) -> Tuple[List[Tuple[int, int, int, int]], List[Dict]]:
    """Находит квадраты на изображении и возвращает как принятые, так и отсеянные."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    thresh = cv2.adaptiveThreshold(
        blurred, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV, 31, 5
    )

    kernel = np.ones((3, 3), np.uint8)
    processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)

    contours, _ = cv2.findContours(processed, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

    squares = []
    rejected = []

    for cnt in contours:
        epsilon = 0.02 * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, epsilon, True)
        x, y, w, h = cv2.boundingRect(cnt)
        area = w * h
        aspect_ratio = float(w) / h
        vertices = len(approx)

        reject_reason = None

        if vertices != 4:
            reject_reason = f"Не 4 вершины ({vertices})"
        elif area < min_area:
            reject_reason = f"Малая площадь ({area} < {min_area})"
        elif area > max_area:
            reject_reason = f"Большая площадь ({area} > {max_area})"
        elif aspect_ratio < 0.8 or aspect_ratio > 1.2:
            reject_reason = f"Неподходящее соотношение сторон ({aspect_ratio:.2f})"
        elif not cv2.isContourConvex(approx):
            reject_reason = "Не выпуклый контур"

        if reject_reason:
            rejected.append({
                "position": (x, y, w, h),
                "area": area,
                "aspect_ratio": aspect_ratio,
                "vertices": vertices,
                "reason": reject_reason
            })
        else:
            squares.append((x, y, w, h))

    squares.sort(key=lambda s: s[0])

    if debug:
        debug_img = image.copy()
        for item in rejected:
            x, y, w, h = item["position"]
            cv2.rectangle(debug_img, (x, y), (x + w, y + h), (0, 0, 255), 1)
        for i, (x, y, w, h) in enumerate(squares, 1):
            cv2.rectangle(debug_img, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(debug_img, str(i), (x, y - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        show_image("Accepted (green) vs Rejected (red)", debug_img)

    return squares, rejected


def process_squares(input_folder: str, output_folder: str, model, device, debug: bool = False):
    """Обрабатывает все изображения в папке для поиска квадратов и предсказывает."""
    os.makedirs(output_folder, exist_ok=True)

    for filename in os.listdir(input_folder):
        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            continue

        try:
            file_path = os.path.join(input_folder, filename)
            image = cv2.imread(file_path)

            if image is None:
                print(f"Ошибка загрузки: {filename}")
                continue

            squares, _ = find_squares(image, debug=debug)

            base_name = os.path.splitext(filename)[0]
            for i, (x, y, w, h) in enumerate(squares, 1):
                square_img = image[y:y + h, x:x + w]
                square_filename = f"{base_name}_square_{i}.jpg"
                output_path = os.path.join(output_folder, square_filename)
                cv2.imwrite(output_path, square_img)

                # Предсказание и добавление к имени файла
                prediction = predict_image(output_path, model, device)
                if prediction == 0:
                    new_filename = f"{base_name}_square_{i}_empty.jpg"
                else:
                    new_filename = f"{base_name}_square_{i}_marked.jpg"

                new_path = os.path.join(output_folder, new_filename)
                os.rename(output_path, new_path)  # Переименовываем файл
                print(f"Обработан квадрат {i} в {filename}, результат: {new_filename}") # это можно убрать


        except Exception as e:
            print(f"Ошибка в файле {filename}: {str(e)}")


def process_answer_sheet(
        input_path: str,
        output_norm_folder: str,
        output_rectangles_folder: str,
        output_squares_folder: str,
        model,  # Добавляем модель как аргумент
        device, # Добавляем device
        debug: bool = False
):
    """Полный процесс обработки бланка."""
    os.makedirs(output_norm_folder, exist_ok=True)
    os.makedirs(output_rectangles_folder, exist_ok=True)
    os.makedirs(output_squares_folder, exist_ok=True)

    if os.path.isdir(input_path):
        input_files = glob.glob(os.path.join(input_path, "*.jpg"))
    else:
        input_files = [input_path]

    for input_file in input_files:
        try:
            print(f"\nНачинаем обработку: {input_file}")

            base_name = os.path.splitext(os.path.basename(input_file))[0]
            norm_output_path = os.path.join(output_norm_folder, f"{base_name}_norm.jpg")

            # 1. Загрузка и предварительная обработка
            image, gray = load_and_preprocess_image(input_file)
            if debug:
                show_image("Original", image)

            # 2. Поиск маркеров
            markers = find_markers(gray, debug=debug)
            print(f"Найдено маркеров: {len(markers)}")

            # 3. Нормализация изображения
            normalized = normalize_image(image, markers, norm_output_path, debug=debug)
            if normalized is None:
                print("Невозможно выполнить нормализацию - проверьте маркеры")
                continue

            if debug:
                show_image("Normalized", normalized)

            # 4. Извлечение прямоугольников
            rectangles = extract_numbered_rectangles(
                norm_output_path,
                output_rectangles_folder,
                debug=debug,
                expected_count=20,
                min_area=20000,
                max_area=50000,
                aspect_ratio_range=(4.5, 7.5)
            )

            # 5. Обработка прямоугольников для поиска квадратов
            process_squares(
                output_rectangles_folder,
                output_squares_folder,
                model,  # Передаем модель
                device, # Передаем device
                debug=debug
            )

            print(f"Успешно обработан файл: {input_file}")

        except Exception as e:
            print(f"Ошибка при обработке файла {input_file}: {str(e)}")


if __name__ == "__main__":
    # Загрузка модели и определение device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CustomResNet().to(device) # Инициализируем модель
    model.load_state_dict(torch.load("best_model.pth", map_location=device)) # Загружаем веса

    input_folder = "jpg"  # Папка с исходными изображениями
    output_norm_folder = "norm_img"  # Папка для нормализованных изображений
    output_rectangles_folder = "rectangles_output"  # Папка для прямоугольников
    output_squares_folder = "squares_output"  # Папка для квадратов

    process_answer_sheet(
        input_folder,
        output_norm_folder,
        output_rectangles_folder,
        output_squares_folder,
        model,  # Передаем загруженную модель
        device, # Передаем device
        debug=False  # Переключите на False для "боевого" режима
    )